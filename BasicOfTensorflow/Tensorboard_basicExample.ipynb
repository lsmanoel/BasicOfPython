{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tensorboard_basicExample.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lsmanoel/BasicOfPython/blob/master/BasicOfTensorflow/Tensorboard_basicExample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "0S0zKJ2PQzaL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Quick guide to run TensorBoard in Google Colab\n",
        "\n",
        "from [dlology.com](https://www.dlology.com/blog/quick-guide-to-run-tensorboard-in-google-colab/)\n",
        "\n",
        "The Google Colab virtual machine is running on a local network located in a Google's server that could be anywhere in the world. This virtual machine is a unix system that have a firewall. This firewall blocks to access the TensorBoard page from Google Colab virtual machine server. Through the [ngrok](https://ngrok.com/) service we able to tunnel the connection to Colab server.\n",
        "\n",
        "![alt text](https://gitcdn.xyz/cdn/Tony607/blog_statics/d425c3fe4cf0d92067572e25ae6cc3198d51936b//images/ngrok/ngrok.jpg)"
      ]
    },
    {
      "metadata": {
        "id": "azU628AqRGYf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Setup ngrok and run TensorBoard on Colab:**\n",
        "\n",
        "Ngrok executable can be directly downloaded to your Colab notebook, run those two lines of code."
      ]
    },
    {
      "metadata": {
        "id": "aMSD_TkhQl5_",
        "colab_type": "code",
        "outputId": "22c3d0b1-03b4-487f-f2df-2957bc02a9ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-01-21 13:34:50--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 52.200.123.104, 52.2.175.150, 52.203.102.189, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|52.200.123.104|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5363700 (5.1M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip.1’\n",
            "\n",
            "\r          ngrok-sta   0%[                    ]       0  --.-KB/s               \rngrok-stable-linux- 100%[===================>]   5.11M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2019-01-21 13:34:50 (42.1 MB/s) - ‘ngrok-stable-linux-amd64.zip.1’ saved [5363700/5363700]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "replace ngrok? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Fx5dZDyoUgZW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "After this, the executable file ngrok will be extracted to the current directory.\n",
        "\n",
        "Next, let's fire up the TensorBoard in the background like this:"
      ]
    },
    {
      "metadata": {
        "id": "3nfgr0m4Uf4H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "LOG_DIR = 'log'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hT0h5gIeU3wn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "It is assuming the TensorBoard log path is \"./log\", where we are going to tell Keras to log files.\n",
        "\n",
        "Then, we can run ngrok to tunnel TensorBoard port 6006 to the outside world. This command also runs in the background."
      ]
    },
    {
      "metadata": {
        "id": "RRZyBGZMVC6m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "POsxV0d1VGAN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "One last step, we get the public URL where we can access the colab TensorBoard web page."
      ]
    },
    {
      "metadata": {
        "id": "kFm86ldVVFTN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vHg0zipoVWR_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This will output a URL you can click on, but wait! We haven't trained our model, so you not get any information from TensorBoard yet."
      ]
    },
    {
      "metadata": {
        "id": "w-yYIrstW3T3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**TensorBoard for Keras:**\n",
        "\n",
        "In this section, we will start training a Keras model and ask Keras to output TensorBoard log files to the ./log directory.\n",
        "\n",
        "Keras output TensorBoard log files by callbacks, which allows you to visualize dynamic graphs of your training and test metrics, as well as activation histograms for the different layers in your model. You can choose whether to visualize individual components and even how frequently you want Keras to activation and weight histograms. The following code will allow you to visualize all available components of our Keras model. The model itself is a simple two layers of 3x3 convolutional followed by 2 Dense layers to classify MNIST handwritten digits dataset."
      ]
    },
    {
      "metadata": {
        "id": "zsRSsA_pXxWQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''Trains a simple convnet on the MNIST dataset.\n",
        "\n",
        "Gets to 99.25% test accuracy after 12 epochs\n",
        "(there is still a lot of margin for parameter tuning).\n",
        "16 seconds per epoch on a GRID K520 GPU.\n",
        "'''\n",
        "\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "from keras.callbacks import TensorBoard\n",
        "\n",
        "batch_size = 10000\n",
        "num_classes = 10\n",
        "epochs = 3\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# the data, shuffled and split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "tbCallBack = TensorBoard(log_dir='log', histogram_freq=1,\n",
        "                         write_graph=True,\n",
        "                         write_grads=True,\n",
        "                         batch_size=batch_size,\n",
        "                         write_images=True)\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test),\n",
        "          callbacks=[tbCallBack])\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Coa-rdpXZqoq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# A short tour to TensorBoard"
      ]
    },
    {
      "metadata": {
        "id": "zwJsHqmSZyff",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**SCALARS:**\n",
        "\n",
        "In this tab, you can see four graphs, acc, loss, acc_val, and loss_val, representing training accuracy, training loss, validation accuracy and validation loss. During an ideal training process, we are expecting the accuracies to increase, and losses decrease over time. However, if you see the validation accuracy start to going downhill after training for some specific epochs. Your model might get overfit on the training sets. I have a quick [Two Simple Recipes for Over Fitted Model](https://www.dlology.com/blog/two-simple-recipes-for-over-fitted-model/). While there are other reasons why a model gets overfit, one apparent reason is the training data is too small, and the solution is either find or generate more data.\n",
        "\n",
        "![alt text](https://gitcdn.xyz/cdn/Tony607/blog_statics/d425c3fe4cf0d92067572e25ae6cc3198d51936b//images/ngrok/scalars.png)\n",
        "\n",
        "Our model's losses and accuracies match our expectation."
      ]
    },
    {
      "metadata": {
        "id": "-PrPygMDadfv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**HISTOGRAMS:**\n",
        "\n",
        "This tab displays the distribution of activation weights, bias, gradients histograms for different layers in your model. One way this graph can be useful is by visualizing the value of gradients we can tell if a model is suffered from vanishing/exploding gradients, give my previous post a read How to deal with Vanishing/Exploding gradients in Keras.\n",
        "\n",
        "![alt text](https://gitcdn.xyz/cdn/Tony607/blog_statics/d425c3fe4cf0d92067572e25ae6cc3198d51936b//images/ngrok/histograms_conv2d_1.png)\n",
        "\n",
        "For other tabs, graphs tab shows the computation graph, more useful if you are building a custom layer or loss function. Image tab visualizes the model weights as images.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "wXGPfIU3aqxH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Summary and further reading:**\n",
        "\n",
        "You learned how to run TensorBoard on a Google Colab notebook and access it on your local machine by leveraging the free ngrok tunneling service.\n",
        "\n",
        "One bonus, alternatively you can run the following code in Colab to use localtunnel instead of ngrok."
      ]
    },
    {
      "metadata": {
        "id": "RXWZLsXMa2oQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "LOG_DIR = './log'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "# Install\n",
        "! npm install -g localtunnel\n",
        "\n",
        "# Tunnel port 6006 (TensorBoard assumed running)\n",
        "get_ipython().system_raw('lt --port 6006 >> url.txt 2>&1 &')\n",
        "\n",
        "# Get url\n",
        "! cat url.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xGoZq0I9a34r",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To develop more understanding of configuring TensorBoard with Keras, refer to the [official document](https://keras.io/callbacks/#tensorboard), you can disable some of the unwanted features to speed up the training since generating logs for TensorBoard takes a substantial amount of time.\n",
        "\n"
      ]
    }
  ]
}